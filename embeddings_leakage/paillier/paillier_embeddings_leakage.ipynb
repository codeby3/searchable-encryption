{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/codeby3/searchable-encryption/blob/main/zilliz/paillier/zilliz_paillier_vector_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vd26fRC07BGs"
   },
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ele1IiqmR5O7",
    "outputId": "45249f20-8e66-4f81-d78c-fb73dfb12607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/228.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.1/228.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.0/288.0 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
      "grpcio-status 1.71.0 requires grpcio>=1.71.0, but you have grpcio 1.67.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU beir sentence-transformers pymilvus datasets phe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CsT0EcFZBh_w",
    "outputId": "4d517dda-12e3-4b9f-c648-db173a697a6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m905.3/905.3 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m122.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1+cu118 which is incompatible.\n",
      "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --quiet torch torchvision --extra-index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zUKH5xL6yQY-",
    "outputId": "587c775d-7f8f-4422-9c70-f46d2c7cd98a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/beir/util.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from beir import util\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "import pandas as pd\n",
    "from pymilvus import MilvusClient, FieldSchema, DataType, CollectionSchema, Collection\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from google.colab import userdata\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zWuFcxpXtfW6"
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.getcwd())\n",
    "import paillier\n",
    "from paillier import PaillierKey, encrypt_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wxlesdmxtoeC"
   },
   "outputs": [],
   "source": [
    "PAILLIER_N_LENGTH = 1024 # Key length for Paillier encryption\n",
    "PAILLIER_SCALING_FACTOR = 1000 # Scaling factor for float to int conversion in Paillier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WX4g3veJMmHY"
   },
   "outputs": [],
   "source": [
    "paillier_key = paillier.generate_random_key(n_length=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgaeW_U57GEJ"
   },
   "source": [
    "# Load Datasets\n",
    "We're using 3 datasets from the BEIR datasets - nfcorpus, fiqa and scidocs (https://huggingface.co/datasets/BeIR/beir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9nzKsJgx31vU"
   },
   "outputs": [],
   "source": [
    "datasets_to_load = [\"nfcorpus\", \"fiqa\", \"scidocs\"]\n",
    "beir_data_path = \"./beir_datasets\" # Local directory to store BEIR data\n",
    "os.makedirs(beir_data_path, exist_ok=True)\n",
    "loaded_beir_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 750,
     "referenced_widgets": [
      "42cafc920fcd4a4cbf905ecef24b341b",
      "e6fac8619b0640888860372734822bb9",
      "b752150209c349778f0c0d28b145d0e7",
      "381363c9828241279bce1c1e00af5170",
      "f40da07075d9450eb73b0d00bbca81b0",
      "e12ac2e83dcd440b9a77baf4ba4afa16",
      "fd96d3655f4a4689a592b5cb93eb6808",
      "bef1a5c5c1a0464b92181da073bc8f2f",
      "cb8917fe9e514800b9f6484131486bc0",
      "8bcf2fe0d4c0476d888da0c94da16a67",
      "fe80f42f37fd42be91b30c80ff15ed1c",
      "c195757c0e534752a63f1794efe52f02",
      "4849ab71cc074eb19b8a8b047e79dea1",
      "fc108d4a50c14b1aac80080c65fccac2",
      "ac95381d1f1644e89adb8261cd1af36e",
      "f00244b59a744116b22a4af44f191b9b",
      "a0ecfb5ea8224ee195c17578863cb742",
      "b4fa94c5b4ad4df684049571a979137e",
      "c614c15de1e6495093ba195e709a51a7",
      "85e5056e5f514afeb6a56b289fa48440",
      "12f8e92804d248c9a1175111b0caf78b",
      "bd83e8bf31754f5196eb82b83476ba40",
      "4456b8563e7d4ed6a20dde7d012b3895",
      "f6cb51aceac94461b6ac557390b689f0",
      "9ee50cedf4f34fb2b1a22e7b1ad30742",
      "64b38fd7d2854956a76f00f1d58ff7f5",
      "9226db5033b44d47a2dccb12dd150ab2",
      "eb11d445dd1c4939affc96847a3b116f",
      "bff93437b112470d96f27472144fb140",
      "397df0946c64469cb113bb28ba12342a",
      "e328daecdcb345c0b7dd1ef45ffba709",
      "5a0aeb2791e0434c91552b2cdf2f5ca4",
      "7169bc0eac7a4930b921831d61641eaa",
      "8759afe664b64d7f801dee4c0aa20faf",
      "f743db8437c44e679fdfa8243ac3c23c",
      "0a83eaba46424674b231c8db645b7e44",
      "0d33f48a4fee4a1a9e4248bb142d19dd",
      "f3cade3f839d445d838de4b398517792",
      "cee733e14d2c4014a6183a42a8b3a954",
      "c1d3f5d9145447d59924a1a5397a7d89",
      "e0632cb46e0b43b7a80f31fb0d9a102d",
      "ab46efd6a1e547d187ea8ba6c39a4823",
      "899f4fe430824369b67df9d00763db3d",
      "95c022a41d6a4efb9bc95291a1642803",
      "cfb1bf67c05d48d08c6725eb36112362",
      "0442bd4ab3ff4c9393da4df04984e294",
      "7ec3564ebcaa4b75b2b3064b8d794c3a",
      "d700c1b2bbbd4a079231bd55b5e1c04c",
      "3f9f4e0a7d1e40a38ab4b48ff093e8c4",
      "f8a7539adf284128bc202ec7c67692ad",
      "a51c681d3b714afbb4a8d6c2bd28c3bf",
      "c4ef49bf4a894578b3499d2ffc0c7160",
      "4fb0ca84be794d08902849b5e04f737a",
      "2deb48cac3b948799eca0153928fb2dc",
      "b1015883d3f0414facb3c849318f589f",
      "56f25a3c255d4627b10b2914eef44847",
      "60f7a8966c3843cc991cc094349db45f",
      "b22abd88da954d2db3dd9a2d08eae0ea",
      "96f033f3f690462ba8bb745c0f32642b",
      "fb98447b488147c19771086dfb1a1c31",
      "12d38e9c7bdf4e06a7539c3943ee4caf",
      "0d1549c73e7b400683073ac87cac47bb",
      "469458037eb94ecca798040e2947a53c",
      "2806fed48def4307a5b1cdac483a3949",
      "379ba98014c247bdb5bac7ad82ec1f9b",
      "e104b1cec3f04d64adf87e49df988da0"
     ]
    },
    "id": "VJJq83bw4NJ3",
    "outputId": "e77ef768-0103-4918-8ccf-f36ae2cda764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing dataset: nfcorpus\n",
      "Downloading nfcorpus from https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/nfcorpus.zip to ./beir_datasets/nfcorpus...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cafc920fcd4a4cbf905ecef24b341b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "./beir_datasets/nfcorpus/nfcorpus.zip:   0%|          | 0.00/2.34M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded nfcorpus to: ./beir_datasets/nfcorpus/nfcorpus\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c195757c0e534752a63f1794efe52f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data for nfcorpus.\n",
      "  Corpus size: 3633 documents\n",
      "  Queries size: 323 queries\n",
      "  Qrels size: 323 relevance judgments\n",
      "  Sample corpus entry (MED-10): Statin Use and Breast Cancer Survival: A Nationwide Cohort Study from Finland - Recent studies have suggested that statins, an established drug group in the prevention of cardiovas...\n",
      "  Sample query entry (PLAIN-2): Do Cholesterol Statin Drugs Cause Breast Cancer?...\n",
      "\n",
      "Processing dataset: fiqa\n",
      "Downloading fiqa from https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/fiqa.zip to ./beir_datasets/fiqa...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4456b8563e7d4ed6a20dde7d012b3895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "./beir_datasets/fiqa/fiqa.zip:   0%|          | 0.00/17.1M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded fiqa to: ./beir_datasets/fiqa/fiqa\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8759afe664b64d7f801dee4c0aa20faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data for fiqa.\n",
      "  Corpus size: 57638 documents\n",
      "  Queries size: 648 queries\n",
      "  Qrels size: 648 relevance judgments\n",
      "  Sample corpus entry (3):  - I'm not saying I don't like the idea of on-the-job training too, but you can't expect the company to...\n",
      "  Sample query entry (8): How to deposit a cheque issued to an associate in my business into my business account?...\n",
      "\n",
      "Processing dataset: scidocs\n",
      "Downloading scidocs from https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/scidocs.zip to ./beir_datasets/scidocs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb1bf67c05d48d08c6725eb36112362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "./beir_datasets/scidocs/scidocs.zip:   0%|          | 0.00/136M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded scidocs to: ./beir_datasets/scidocs/scidocs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f25a3c255d4627b10b2914eef44847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data for scidocs.\n",
      "  Corpus size: 25657 documents\n",
      "  Queries size: 1000 queries\n",
      "  Qrels size: 1000 relevance judgments\n",
      "  Sample corpus entry (632589828c8b9fca2c3a59e97451fde8fa7d188d): A hybrid of genetic algorithm and particle swarm optimization for recurrent network design - An evolutionary recurrent network which automates the design of recurrent neural/fuzzy networks usin...\n",
      "  Sample query entry (78495383450e02c5fe817e408726134b3084905d): A Direct Search Method to solve Economic Dispatch Problem with Valve-Point Effect...\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets_to_load:\n",
    "    print(f\"\\nProcessing dataset: {dataset_name}\")\n",
    "\n",
    "    # Step 3a: Download the dataset\n",
    "    url = f\"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{dataset_name}.zip\"\n",
    "    out_dir = os.path.join(beir_data_path, dataset_name)\n",
    "\n",
    "    if not os.path.exists(out_dir):\n",
    "        print(f\"Downloading {dataset_name} from {url} to {out_dir}...\")\n",
    "        data_path = util.download_and_unzip(url, out_dir)\n",
    "        print(f\"Downloaded {dataset_name} to: {data_path}\")\n",
    "    else:\n",
    "        print(f\"Dataset {dataset_name} already exists at {out_dir}. Skipping download.\")\n",
    "        data_path = out_dir\n",
    "\n",
    "    # Step 3b: Load the corpus, queries, and qrels\n",
    "    try:\n",
    "        corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")\n",
    "        loaded_beir_data[dataset_name] = {\n",
    "            \"corpus\": corpus,\n",
    "            \"queries\": queries,\n",
    "            \"qrels\": qrels\n",
    "        }\n",
    "        print(f\"Successfully loaded data for {dataset_name}.\")\n",
    "        print(f\"  Corpus size: {len(corpus)} documents\")\n",
    "        print(f\"  Queries size: {len(queries)} queries\")\n",
    "        print(f\"  Qrels size: {len(qrels)} relevance judgments\")\n",
    "\n",
    "        # Print a sample document and query to verify\n",
    "        if len(corpus) > 0:\n",
    "            sample_doc_id = list(corpus.keys())[0]\n",
    "            print(f\"  Sample corpus entry ({sample_doc_id}): {corpus[sample_doc_id]['title']} - {corpus[sample_doc_id]['text'][:100]}...\")\n",
    "        if len(queries) > 0:\n",
    "            sample_query_id = list(queries.keys())[0]\n",
    "            print(f\"  Sample query entry ({sample_query_id}): {queries[sample_query_id][:100]}...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {dataset_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyX-XNJKDDUK"
   },
   "source": [
    "## Using subsets of data\n",
    "Using Subsets of data because full data is taking infeasibly long for Paillier implementaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kD2npVJTDLCn"
   },
   "outputs": [],
   "source": [
    "# Using 10% of the queries as a starting point.\n",
    "SUBSET_QUERY_PERCENTAGE = 0.05\n",
    "RANDOM_SEED = 42 # Fixed seed for reproducibility\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "subset_beir_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tExMf2DoIFS0",
    "outputId": "b499f987-95df-47e9-cd21-ba4a48c38739"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating subset for dataset: nfcorpus\n",
      "  Selected 16 queries (out of 323)\n",
      "  Selected 713 documents relevant to the query subset.\n",
      "  Filtered qrels to 16 queries with relevant documents in the new corpus subset.\n",
      "\n",
      "Creating subset for dataset: fiqa\n",
      "  Selected 32 queries (out of 648)\n",
      "  Selected 100 documents relevant to the query subset.\n",
      "  Filtered qrels to 32 queries with relevant documents in the new corpus subset.\n",
      "\n",
      "Creating subset for dataset: scidocs\n",
      "  Selected 50 queries (out of 1000)\n",
      "  Selected 241 documents relevant to the query subset.\n",
      "  Filtered qrels to 50 queries with relevant documents in the new corpus subset.\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, data in loaded_beir_data.items():\n",
    "    print(f\"\\nCreating subset for dataset: {dataset_name}\")\n",
    "\n",
    "    corpus = data[\"corpus\"]\n",
    "    queries = data[\"queries\"]\n",
    "    qrels = data[\"qrels\"]\n",
    "\n",
    "    # Create a subset of queries\n",
    "    num_queries_subset = int(len(queries) * SUBSET_QUERY_PERCENTAGE)\n",
    "    query_ids = list(queries.keys())\n",
    "    # Ensure there are queries to sample from\n",
    "    if num_queries_subset > 0 and len(query_ids) >= num_queries_subset:\n",
    "        subset_query_ids = set(random.sample(query_ids, num_queries_subset))\n",
    "    else:\n",
    "        subset_query_ids = set(query_ids) # Use all if subset is too small or percentage is 100%\n",
    "\n",
    "    subset_queries = {qid: queries[qid] for qid in subset_query_ids}\n",
    "    print(f\"  Selected {len(subset_queries)} queries (out of {len(queries)})\")\n",
    "\n",
    "    # Create a corpus subset containing only relevant documents for the query subset\n",
    "    # This is a better approach than random corpus sampling for ensuring evaluation is meaningful.\n",
    "    relevant_corpus_ids = set()\n",
    "    for qid in subset_query_ids:\n",
    "        if qid in qrels:\n",
    "            for doc_id, score in qrels[qid].items():\n",
    "                if score > 0: # A score > 0 indicates relevance\n",
    "                    relevant_corpus_ids.add(doc_id)\n",
    "\n",
    "    # Filter the main corpus to only include these relevant documents\n",
    "    subset_corpus = {cid: corpus[cid] for cid in relevant_corpus_ids if cid in corpus}\n",
    "    print(f\"  Selected {len(subset_corpus)} documents relevant to the query subset.\")\n",
    "\n",
    "    # Filter qrels to match the new query and corpus subsets\n",
    "    subset_qrels = {}\n",
    "    for qid, doc_scores in qrels.items():\n",
    "        if qid in subset_query_ids: # Only consider queries in our subset\n",
    "            filtered_scores = {did: score for did, score in doc_scores.items() if did in subset_corpus}\n",
    "            if filtered_scores: # Only add the query if it has relevant docs in the subset\n",
    "                subset_qrels[qid] = filtered_scores\n",
    "    print(f\"  Filtered qrels to {len(subset_qrels)} queries with relevant documents in the new corpus subset.\")\n",
    "\n",
    "\n",
    "    # Store the new subset data\n",
    "    subset_beir_data[dataset_name] = {\n",
    "        \"corpus\": subset_corpus,\n",
    "        \"queries\": subset_queries,\n",
    "        \"qrels\": subset_qrels\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kKr-cGF7ef5"
   },
   "source": [
    "Using all-MiniLM-L6-v2 embedding model from HuggingFace SentenceTransformers Library. It generates embeddings of 384 dimensions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528,
     "referenced_widgets": [
      "489c090b0ec44666913ebf1d7f204001",
      "0c9fd73e628c43c89cd9e97ab1a5a42f",
      "e6175e56b7c6407faafa85bfa39672af",
      "039486d895634473890b8ac082b5d6e4",
      "bcac228b1593402fb4f5d0d80043b462",
      "f7bc1b305f44433698f33dbe72ebb813",
      "4496ab7a193e4dc0bf8ac246c79fbb46",
      "483e5dc0464945ec9eef5e6ea6859a16",
      "26d1954a550145f7915dde456578536f",
      "68e05f01cf874251b54afe6981729dc2",
      "e24e7c919dc7482bbde268e0bb7acb03",
      "50c50b0784f6451db6e76ffe6a328020",
      "26cc24ad56654910b380aa77d1c6c134",
      "07961dc7560f4092815a9e0c2b2c5552",
      "6c14ba2bd4364b83a8d99279d6726635",
      "f4f4bc74f6934640a22d14be3281a714",
      "f8fe686079714af1b599c9192ac687db",
      "f3413ce6e5864ed1b8ebe45c3f69658c",
      "3ebaf86520954d32a37d46adb1be5c9b",
      "9dcd6175ceb14ef2a4a6ad7f0f2930b8",
      "04676820fccd4e448b80f94f8153e8ab",
      "0379ce9b16e9441a91580721ad0c66e0",
      "8a75f3778a4c405fb49dc49f03884668",
      "f8bce1741cca4f6aaef4ba6dca045976",
      "1570fd6d2c344afb9aabd56eacd066e9",
      "759711ca9b1642ce9d3442a931d381d6",
      "23aff4a0af8e4d00ab672811f09df2d0",
      "00db1fe19fac4e6d9280ed66a3fdcfa8",
      "e7e6559183ee4154b4d1f6f86952a4aa",
      "20d6b01969b8455d90fb668f02d314e6",
      "e8d04726822142dc9dc5e1c89d0e7c2c",
      "cb77b7507f5a47ff88e9443b1ea2a239",
      "f6ff7255f80d4af98c90ce12406ed8cc",
      "01b3dae73f1a41059c502a23df28e689",
      "458540c574a44b3c8d92833c45ba7501",
      "ba25bb2975fe4d3ab01f4b066a788330",
      "f1daa11ab34f4797b7d1a0a552786b8e",
      "b5937e5875604c2e896feef223d6aaa4",
      "5aa5c7c5e2fb4f4d836725e43f0eb038",
      "b80073b215b44326a5a058ccf04f28c9",
      "b890461df4094cfe83ed8c811dcc8f55",
      "75e1b246bd5249cc92e254d15bca02cf",
      "be7db7a0c22f4b549256a42b51831751",
      "f1d0e359eb5b4869a56a36a0cec5c2f1",
      "247b961db6de448687052729d94d2e93",
      "42bc8720353d4e28b8d0160dae633b4e",
      "ca50c600b93140d18b3e3b6c11c05a98",
      "ff86156681f24693af176afe2aa40107",
      "f6868c068349485e8e39e2ff9f132470",
      "4ef6a50a22bb4453a087cd364896fadd",
      "ecf4ac4f323840b88c632c29cf334233",
      "53738a20fc0b4fdaa62a43efdf8ff9b8",
      "535cfe62d72446fba0945984829c2076",
      "b0ce89ec6435413bbc2893b9360aa1db",
      "02929e6e03e94d99931a95b270c2d704",
      "27ebe443eb2b40ce8f58fab6d29add3b",
      "675160c5dc3c4ca28d02f10946fefc34",
      "9b32ac64420d415bbc452821611c707f",
      "31fff73d5c054e94b7c81ebd59219599",
      "1f8cc01305f043dea3ee40e81777405a",
      "f6d855fd92cd4627b88e9ae91076e348",
      "9383019dc7884a9a8473859c57f7f9a0",
      "4d1d7107e71242afafe6cfcb6c6b6b6f",
      "168e035e18d346d0bdfea7b7d8c0b2dd",
      "7be660bf012f45b8b06c2b7575daf67a",
      "fedc040f632a43f480e810f90629e12c",
      "b7ccb53cf13f430aa03d9e0930a42780",
      "dee65d44e09c4e1e8aeec0fed8ff49c8",
      "b98fc2d569d24478bda6c90ead600994",
      "439b6743cbfd4811a57d4427ac4e2ef9",
      "ea4eb006a9224e9fbbfd0ec2f45529ce",
      "530aebfe59e24e4fa1d3cb698f1af9e0",
      "7a3ac0216d1441cc96a22bf6569898ac",
      "d6a810ae5ef4462286a36f7687013018",
      "afe139c0952246b5a1d68f760ae32b75",
      "2b1b6c610092464881a2a10f66577722",
      "3af1d2cdf1f7446cb9306f8deef8b467",
      "936da4393a7d4cd69ec065cd4622ec53",
      "db5448fefb5b47f6b976456b52509a44",
      "64ccdac1f35848b885b556e3681829aa",
      "e0138c4fe2604549bed4710717f31ae8",
      "4dcdb63ceba5457baf2c38324f43879e",
      "c2e878826509487f8a903ade369dfca7",
      "27d8797ce14241dca7f71ec43650ed3e",
      "452fa60db4d94d899d8029ac993be390",
      "3c85df6f75eb432ea774fb511dab4970",
      "3fb6b39992e644ab85afe2b524dd556b",
      "c26f019959334863b420c45f71d2b422",
      "4a7fc7b86a9842e68863e20f37117a47",
      "56f3424b442145809004e6d557ff2ebb",
      "47ac578e5ccd44d99fb1dac66fc7ba91",
      "21dec395834a47fca302e8589eb21d4c",
      "ef6288d5f1dd4a979a5386a4ce787aa0",
      "a5aa2a75f97d44dd94dde561e0876c1a",
      "7088aae9a75c4e359ce938169729f9a7",
      "cf31d4b7e5cd45d3b1e1ddaed6600cd5",
      "5cf95395d61a41acb6290fb83efad94f",
      "6bb30aae5acc4ef4973df04efe048e0a",
      "efdd9a5cd44f4aafbdbb0d611dbc6c4b",
      "d00c898c66d14994ad079a063e9961e6",
      "29f528ce60964bdf8a881d91380e160a",
      "cd2f7c47410242d1aeb22bec084b7080",
      "28ca3df8475e4081a4810f4c5a292c52",
      "d8b8ae3476e6414697b202f03dbec225",
      "076ac54abd584cb6b922adafb7fdcb7d",
      "5b776fde72b0415fbaa366f51c3fe603",
      "87a44aeb19a447be92865dc9371a42cb",
      "b47fcbdda9c242229c9792b55823ae4d",
      "8fe2acfffd87488082674553f9e3bd73",
      "15c28b495932411384f9b10efbd068ad",
      "11f2b9849a804f32bcbd9ee2317b12b2",
      "f69fe9082d3b486c98dc42f3b2fcace6",
      "911074aff1f24d3b8be4d4558812d1e9",
      "441a18ef89454bbbbd125413aba3afa3",
      "606aa9d404204663896149e65fe41d5e",
      "d379db7ab94f4b358c4c4e26d37a2bdb",
      "beb2e9883a7b466eaace499311f4387b",
      "a3696cb546024fa6b0c84364cb07b13d",
      "a5b08acdb43848f3bf3dc67d11042e33",
      "51ee042e9ecd4f639f267bc9914dc47f",
      "a9a101a9f47e4afea22c2577ca60e890"
     ]
    },
    "id": "0vD4EAxbEW01",
    "outputId": "f4abef75-0733-410d-99c2-33006bbcf3fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489c090b0ec44666913ebf1d7f204001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c50b0784f6451db6e76ffe6a328020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a75f3778a4c405fb49dc49f03884668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b3dae73f1a41059c502a23df28e689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247b961db6de448687052729d94d2e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ebe443eb2b40ce8f58fab6d29add3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ccb53cf13f430aa03d9e0930a42780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936da4393a7d4cd69ec065cd4622ec53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7fc7b86a9842e68863e20f37117a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00c898c66d14994ad079a063e9961e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f2b9849a804f32bcbd9ee2317b12b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'all-MiniLM-L6-v2' loaded successfully on cuda.\n",
      "Model output dimension: 384\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the model\n",
    "try:\n",
    "    embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)\n",
    "    print(f\"Model 'all-MiniLM-L6-v2' loaded successfully on {device}.\")\n",
    "    # Verify model output dimension (all-MiniLM-L6-v2 has 384 dimensions)\n",
    "    dummy_embedding = embedding_model.encode(\"test sentence\")\n",
    "    print(f\"Model output dimension: {len(dummy_embedding)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load embedding model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDb7ObBl7wFX"
   },
   "source": [
    "Batch ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZUheTEgNFARP"
   },
   "outputs": [],
   "source": [
    "DIMENSION = 384 # Dimension for all-MiniLM-L6-v2\n",
    "BATCH_SIZE = 64\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "ingestion_metrics = {}\n",
    "PAILLIER_SCALING_FACTOR = 10**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "maDYKxsJZay3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
